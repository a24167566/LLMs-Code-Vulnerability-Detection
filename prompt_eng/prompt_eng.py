import json
import openai
from openai import OpenAI

METHOD = ""
MODEL = ""

def query_llm(prompt):
    client = OpenAI()

    try:
        completion = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "user", 
                    "content": prompt
                }
            ]
        )

        response = completion.choices[0].message.content

    except openai.BadRequestError as e:
        response = "Error"

    return response

def modify(prompt, function):
    f = open("./prompt_eng/prompt_template.json", "r")
    techniques = json.load(f)
    modified_prompt = ""

    if function == "generation":
        role = "From now on, you are an excellent security-aware developer that does not write code with vulnerabilities.\n"
        instruction = ""
        output_indicator = "Don't return a preamble or suffix, just the code."
        context = "You are asked to write security-aware code that does not contain vulnerabilities."
        style = "Provide answer based on the SEI CERT Coding Standards."
    elif function == "detection":
        role = "From now on, you are an excellent cybersecurity expert that can analyse given code and determine if it is vulnerable or safe, and if vulnerable identify the related CWE.\n"
        instruction = "Analyse the provided code and determine if the code is vulnerable or safe, if vulnerable identify the most obvious CWE.\n"
        output_indicator = "Analysis of the code and your determination of whether the code is vulnerable or safe. If the code is vulnerable, include the most obvious CWE in your analysis."
        context = "You are asked to accurately detect if a code is vulnerable or safe. The vulnerabilities are related to the Common Weakness Enumeration (CWE) list."
        style = "Provide answer based on the Common Weakness Enumeration descriptions and IDs."
    elif function == "fix":
        cwe = prompt[1]
        output_indicator = "Don't return a preamble or suffix, just the code."
        prompt = prompt[0] + "\n" + output_indicator
        instruction = "Review the following code with a CWE vulnerability present. Provide a revised version of the code with the vulnerability resolved.\n"
        role = "From now on, you are an excellent code reviewer that can fix codes with CWE vulnerabilities.\n"
        context = "You are asked to accurately fix a code that contains a vulnerability related to the Common Weakness Enumeration (CWE) list."
        style = "Provide answer based on the SEI CERT Coding Standards."

    if METHOD == "NONE":
        modified_prompt = instruction + prompt
    elif METHOD == "ROLE":
        modified_prompt = role + instruction + prompt
    elif METHOD == "COT":
        modified_prompt = instruction + prompt + "\n" + techniques["COT"]["content"]
    elif METHOD == "APE-COT":
        modified_prompt = instruction + prompt + "\n" + techniques["APE-COT"]["content"]
    elif METHOD == "CO-STAR":
        template = techniques['co-star']
        template["context"]["content"] = context
        template["objective"]["content"] = instruction + prompt
        template["response"]["content"]  = output_indicator
        template["style"]["content"] = style
        for key in template:
            for key2 in template[key]:
                modified_prompt += template[key][key2]
    elif METHOD == "DYNAMIC":
        if function == "fix":
            template = techniques['DYNAMIC']["detection"]
            template["context"]["content"] = context
            template["hint"]["content"] =  "The vulnerability is related to " + cwe + "."
            template["objective"]["content"] = instruction + prompt
            for key in template:
                for key2 in template[key]:
                    modified_prompt += template[key][key2]
        elif function == "generation":
            prediction_prompt = "Based on the instructions below, predict the vulnerabilities that might arise from the resulting code. Return just a brief, concise list of vulnerabilities. Do not return any code.\n" + "Instruction: " + prompt
            prediction =  query_llm(prediction_prompt)
            template = techniques['DYNAMIC']["generation"]
            template["context"]["content"] = context
            template["warning"]["content"] = "Ensure your code is robust and secure. Do not include any of the following vulnerabilities in your output code:\n" + prediction
            template["objective"]["content"] = instruction + prompt
            for key in template:
                for key2 in template[key]:
                    modified_prompt += template[key][key2]
        elif function == "detection":
            prediction_prompt = "Analyse the provided code below and return two lines of text. The first line states the programming language of the code. The second line is a list of potential vulnerabilities based the code's functionality ONLY. Do not return any code.\n" + "Code to analyse:\n" + prompt
            prediction =  query_llm(prediction_prompt)
            if prediction == "Error":
                return "Error"
            template = techniques['DYNAMIC']["detection"]
            template["context"]["content"] = context
            template["hint"]["content"] = "Ensure your analysis is accurate. Use the following information to assist your analysis:\n" + prediction
            template["objective"]["content"] = instruction + prompt
            for key in template:
                for key2 in template[key]:
                    modified_prompt += template[key][key2]
    return modified_prompt